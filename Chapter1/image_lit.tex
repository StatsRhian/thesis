%---------------- COMMENT FOR IMPORTING ----------------------
%\RequirePackage{lineno}				
%\documentclass[12pt]{report}		
%\pagestyle{headings}
%\input{ST-input2}							

%\setcounter{chapter}{1}
%\begin{document}								
%\setpagewiselinenumbers
%\linenumbers
%\tableofcontents
%-------------------------------------------------------------

\chapter{Literature Review}

\section{Image Analysis}
\label{sec:sequ-monte-carlo}




There is a vast amount of research available  in the literature detailing the many techniques for background subtraction; notable comparative studies include \cite{Sen-Ching2004} and \cite{Piccardi2004a}. Generally, algorithms for background modelling  can be categorised into pixel based and region based methods  \cite{Bouwmans2011}. The latter may seem more intuitive as one expects foreground to be clustered and generally not exist as isolated pixels. Using knowledge of neighbouring pixels should therefore improve the classification of pixels into foreground or background, and region based techniques such as  \cite{elgammal2000} and \cite{toyama1999} do use this knowledge to segment the images into regions and then create a background model based on these regions. However, there are downsides to region based techniques, for example they are often a lot more complex to run than pixel based techniques, and are not generally robust to division of blocks.

Pixel-based methods such as approximate median filtering \cite{McFarlane1995} assume that the pixels observed are classified as foreground independently of each other. These methods can often detect the contours of foreground well but may be susceptible to making false classifications, especially if the background model is not well tuned.  

It is also possible to categorise these algorithms as recursive and non-recursive methods \cite{Bouwmans2011}. A non-recursive algorithm maintains a buffer or window of $N$ previous video frames and estimates a background model based on the statistical properties of these frames. This sliding window is usually required to be fairly large in order to obtain accurate results, and therefore can quickly become computationally intensive. Recursive techniques update the background subtraction each time a new frame is stored and so there is no need to buffer previous frames. The method used in Section \ref{sec:backgr-subtr-with} to model the background is a pixel-based, recursive method.

More recently the new technology of Compressive Sensing \cite{Candes2006, Candes2006a, Donoho2006} has been applied to the background subtraction problem. The theory of compressed sensing states that an undersampled signal can be recovered almost perfectly, given that the signal itself is sparse in some domain \cite{Baraniuk2007}, i.e. a large proportion of the signal's elements are close to zero. In compressive sensing for video, a random matrix is used to encode a signal efficiently, and then a recovery algorithm is used to decode the signal and recover the required information fairly accurately. 

Most compressed sensing background subtraction methods \cite{Cevher2008a, Cevher2008b, Warnell2011, Cossalter2009} make the assumption that the majority of the pixels in a video represent the background, and therefore the foreground is sparse in the spatial domain. This key point allows us to encode a video into a low dimension and then search for a sparse solution, using the knowledge that the foreground mask should be suitably sparse. 

The background subtraction problem is first expressed as a sparse signal recovery problem in \cite{Cevher2008b}. Their work successfully recovers silhouettes of foreground activity by modelling a compressed form of the background and recovering a foreground mask directly from compressed measurements. Later \cite{Warnell2011} builds upon this work by proposing a method that adapts the encoding process between frames to incorporate the changing size of foreground. Unlike \cite{Cevher2008b}, the authors of \cite{Warnell2011} choose to use a static model for the background which could cause problems in the model when applying to real-life video. 

More current work has started attempting to incorporate the structure of foreground into segmentation. It is generally expected that foreground will be clustered into particular shapes in most frames and does not consist of isolated pixels. Foreground often consists of humans, animals and vehicles, and so knowledge of this structure could be used to improve segmentation. Currently many different approaches are being investigated such as applying particle filters \cite{Cossalter2009} and lattice based graphical models \cite{Cevher2008a}. Although cluster type methods are not attempted in this work, it is a research area of interest for future investigation. 

%\cite{Qiu2012} have developed a robust recursive PCA type method to seperate foreground and Background. They use PCA to identify the 'outlier' (the foreground) from the low dimensional subspace (background.) Their algorithm entitlted ReProCs is online, and uses deails about the previous foreground to help vpredict the location of the current foreground by taking advatage of the clustering of foreground. This would fail if the foreground appeared from the centre of the image. 

%\cite{Cossalter2009} keeps tracks of object of interest by applying particle filters to the compressed frames, without ever reconstructing the original image (I.E background subtraction is applied during the the projection domain. The SPGL1 algorithm is applied to recover he foreground and the background is modelled in a block based framework. 

%\cite{Liu2010} focusses on a block based approach, which focuses on using inter-frame correlation. One issue that arrises from this technique is that different regions of the image may exhibt different types of inter-frame correlation. Their method reconstructs the entire image and then applies techniques which is inefficient. But they do instigate a foreground detection which is a threshold based method for determining if there exists foreground in the current frame or not.  

%\cite{Lu2010} discusses alot of the literature based on combining CS with tracking type algorithms but does not focus on the efficiency of assuming the staparsity of foreground in the spatial domain. 

%\cite{Zhao2011}bases their work on the assution that the background has a sparse lienar representation over learned dictionary and that the foreground is sparse.  

%Sparse coding based visual tracking
%Has an emphasis on tracking algorithms
%Good discussion or why sparse coding is of value to visual tracking, and if it helps atall. 

%\cite{Cevher2008a}The foreground is often clustered aswell as sparse. We expect foreground to take the shape of a car/vehicle or a person or an animal. Obsiouly this depends on the video we are duscussing but certain could be universal in sandard surveillance footage. (FOOTAGE is all so different / similar). 

%\cite{Li2011} choses to uses hash kernels instead of a random measurement to acquire their signal. Their algorithm uses a customised orthogonal matching pursuit to track foreground. Uses background templates and evalutates all work in terms of the TSP. 

In this work, two recovery algorithms are compared, one greedy method and one based on convex optimisation when applied to a background subtraction algorithm. 
%The proposed work is inspired by \cite{Cevher2008b}, we wish to be able to understand the effects of different recovery algorithms on the performance of background subtraction, and how the sparsity of the real footage can affect the performance of such algorithms. 

%In summary the main contributions made in this paper are: 
%\begin{itemize}
%\item A comparison of recovery algorithms in a compressive sensing for background subtraction setting. 
%\item Better understanding of the effect of sparsity in foreground detection.
%\item Discussion of the advantages of using sparsity properties in video analysis.
%\end{itemize}




%---------------- COMMENT FOR IMPORTING ----------------------
%\pagebreak										
%\bibliographystyle{plainnat}	
%\bibliography{References}		
%\end{document}								
%-------------------------------------------------------------
